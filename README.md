# ğŸ¤– Assistente EstratÃ©gico

O **Assistente EstratÃ©gico** Ã© uma aplicaÃ§Ã£o avanÃ§ada baseada em InteligÃªncia Artificial, desenvolvida com as tecnologias `Streamlit`, `LangChain` e integraÃ§Ã£o com modelos da OpenAI. Esta soluÃ§Ã£o Ã© projetada para fornecer suporte estratÃ©gico, processando perguntas e oferecendo respostas contextuais fundamentadas em documentos estruturados e prÃ©-processados.

---

## ğŸš€ Funcionalidades Principais

- **AnÃ¡lise Contextual Inteligente**: As respostas sÃ£o geradas com base na similaridade semÃ¢ntica de documentos fornecidos, garantindo precisÃ£o e relevÃ¢ncia.
- **Pipeline Modular e Personalizado**: Configurado para processar consultas e buscar contextos relevantes de forma eficiente.
- **Interface de UsuÃ¡rio Intuitiva**: Desenvolvida com `Streamlit`, oferecendo estilizaÃ§Ã£o avanÃ§ada e experiÃªncia interativa.
- **AtualizaÃ§Ã£o AutomÃ¡tica de Dados**: Detecta alteraÃ§Ãµes em documentos e recria o vetor FAISS automaticamente, mantendo os dados atualizados.

---

## ğŸ› ï¸ Estrutura do Projeto

A organizaÃ§Ã£o do projeto segue uma estrutura modular e escalÃ¡vel:

```plaintext
project/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py                   # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”œâ”€â”€ database/
â”‚   â””â”€â”€ vectorstore_handler.py      # Gerenciamento de vectorstore (FAISS)
â”œâ”€â”€ documentation/
â”‚   â””â”€â”€ arquivo.md                  # Documentos Markdown para anÃ¡lise
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ pipeline.py                 # ConfiguraÃ§Ã£o do pipeline de processamento
â”œâ”€â”€ prompt/
â”‚   â””â”€â”€ prompt_template.py          # Template do prompt para a IA
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ faiss_index/
â”‚       â”œâ”€â”€ index.faiss             # Arquivo FAISS index
â”‚       â””â”€â”€ index.pkl               # Metadados do FAISS
â”œâ”€â”€ app.py                          # AplicaÃ§Ã£o principal Streamlit
â”œâ”€â”€ README.md                       # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ venv                            # Ambiente virtual (recomendado)
â”œâ”€â”€ .env                            # VariÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                      # Arquivos ignorados pelo git
â””â”€â”€ requirements.txt                # DependÃªncias do projeto
```

---

## ğŸ”§ PrÃ©-requisitos

Certifique-se de ter as seguintes ferramentas instaladas:

- Python 3.8 ou superior
- `pip` ou `conda` para gerenciamento de pacotes

---

## ğŸ“¦ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/LoboProgrammingg/IA-MARKDOWN
   cd IA-MARKDOWN
   ```

2. **Crie e ative um ambiente virtual**:
   ```bash
   python -m venv venv
   source venv/bin/activate   # Para Linux/Mac
   venv\Scripts\activate      # Para Windows
   ```

3. **Instale as dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure as variÃ¡veis de ambiente**:
   - Crie um arquivo `.env` na pasta raiz do projeto:
     ```
     OPENAI_API_KEY=seu_api_key_aqui
     ```
   - Substitua `seu_api_key_aqui` pela sua chave de API da OpenAI.

---

## ğŸ“‚ ConfiguraÃ§Ã£o de Dados

1. **Arquivo Markdown**:
   - O arquivo `arquivo.md` deve conter dados estruturados para anÃ¡lise pela IA.
   - Estrutura esperada:
     ```markdown
     ## Unidade: Nome da Unidade
     ConteÃºdo relacionado ao meu projeto...

     ## Unidade: Outra Unidade
     Mais informaÃ§Ãµes...
     ```

2. **VectorStore (FAISS)**:
   - O sistema detecta automaticamente mudanÃ§as no arquivo `arquivo.md` e recria o vetor FAISS conforme necessÃ¡rio, garantindo que os dados estejam sempre atualizados.

---

## â–¶ï¸ Como Executar

1. Inicie a aplicaÃ§Ã£o:
   ```bash
   streamlit run app.py
   ```

2. Acesse o navegador no link fornecido pelo terminal (geralmente `http://localhost:8501`).

---

## ğŸ” Pipeline de Processamento

O pipeline, configurado no arquivo `pipeline.py`, segue as etapas abaixo:

1. **Carregamento do VectorStore**:
   - A funÃ§Ã£o `get_vectorstore` no arquivo `vectorstore_handler.py` verifica e atualiza automaticamente o vetor FAISS com base no arquivo Markdown.

2. **ConfiguraÃ§Ã£o do Pipeline**:
   - Utiliza o retriever do FAISS para localizar os contextos mais relevantes.
   - Processa as consultas com o modelo da OpenAI (`gpt-4o-mini`), garantindo respostas precisas e contextualizadas.

3. **Resposta em Streaming**:
   - As respostas sÃ£o geradas em tempo real e exibidas na interface do Streamlit.

---

## ğŸ¨ Interface do UsuÃ¡rio

A interface da aplicaÃ§Ã£o foi projetada com atenÃ§Ã£o ao design e facilidade de uso:

- **Chat Interativo**:
  - Mensagens do usuÃ¡rio e da IA sÃ£o exibidas em balÃµes estilizados.
  - O texto da IA Ã© formatado para destacar palavras-chave como `Unidade`, `Objetivo EstratÃ©gico`, etc.

- **Estilo Visual Personalizado**:
  - Cores, fontes e layout foram ajustados para proporcionar uma experiÃªncia visual agradÃ¡vel e profissional.

---

## âœ¨ Exemplos de Uso

### Entrada do UsuÃ¡rio:
```plaintext
Qual Ã© o objetivo estratÃ©gico da Unidade X?
```

### Resposta da IA:
```plaintext
Unidade: Unidade X

Objetivo EstratÃ©gico: Aumentar a eficiÃªncia operacional...

Perspectiva: Interna
```

---

## ğŸ› ï¸ ManutenÃ§Ã£o e AtualizaÃ§Ã£o

### AtualizaÃ§Ã£o do VectorStore
- Sempre que o arquivo `arquivo.md` for alterado, o sistema detectarÃ¡ as mudanÃ§as e recriarÃ¡ automaticamente o vetor FAISS.

### Adicionando Novas Funcionalidades
- **Prompt**: Edite o arquivo `prompt_template.py` para ajustar o formato ou mensagem padrÃ£o.
- **Modelos**: Atualize o modelo no arquivo `pipeline.py` para utilizar novas versÃµes ou modelos diferentes da OpenAI.

---

## ğŸ§‘â€ğŸ’» Contribuindo

ContribuiÃ§Ãµes sÃ£o sempre bem-vindas! Para contribuir:

1. FaÃ§a um fork do repositÃ³rio.
2. Crie uma nova branch:
   ```bash
   git checkout -b minha-nova-funcionalidade
   ```
3. FaÃ§a suas alteraÃ§Ãµes e envie um pull request.

---

## ğŸ“ Suporte

Se vocÃª tiver dÃºvidas ou precisar de suporte, sinta-se Ã  vontade para abrir uma [issue](https://github.com/LoboProgrammingg/IA-MARKDOWN/issues).
